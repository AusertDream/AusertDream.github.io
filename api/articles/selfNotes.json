{"title":"selfNotes","uid":"e51c6b0cc288c9b94c0f6d165fb0d5e1","slug":"selfNotes","date":"2025-02-28T06:32:22.807Z","updated":"2025-02-28T06:32:22.812Z","comments":true,"path":"api/articles/selfNotes.json","keywords":null,"cover":"https://zh.d2l.ai/_images/front.png","content":"<p>以此note介绍LLM有关的trick或者一些信息差的东西。</p>\n<ol>\n<li>计算loss的时候记得把padding token屏蔽掉，不然模型学的全是padding token，根本不会输出其他token</li>\n<li>LLM的学习率往往很低，不要以为0.0005就已经很小了，如果发现模型收敛到一定的值就不收敛了，试试看减小学习率，让他多训练一会（暴怒）。</li>\n<li>LLM的prompt很重要，问题描述不清楚，往往模型的输出没办法align到你想要的输出。</li>\n<li>数据集记得分一个dev dataset出来，用来方便开发，不然跑一次train dataset跑半天突然来个报错就老实了</li>\n<li>多卡训练模型保存之后，state_dict上会多加一个module标记，这个时候如果想单卡推理，记得module删了，不然dict会对不上。</li>\n<li>transformers库的模型，在生成的时候有generate和chat两个方法，generate是单轮的，chat是多轮对话，注意chat_template。得严格按照模型的template来chat，不然很容易答非所问。此外虽然说LLM是可以多轮对话的，但实际上仍然是线性的，只不过是把history一股脑的给LLM而已，predict next token到结束。查看模型的template可以print(tokenizer.chat_template)查看，不过一般花里胡哨的，瞪眼法看也看不出来啥（</li>\n</ol>\n","feature":false,"text":"以此note介绍LLM有关的trick或者一些信息差的东西。 计算loss的时候记得把padding token屏蔽掉，不然模型学的全是padding token，根本不会输出其他token LLM的学习率往往很低，不要以为0.0005就已经很小了，如果发现模型收敛到一定的值就不...","link":"","photos":[],"count_time":{"symbolsCount":602,"symbolsTime":"1 mins."},"categories":[{"name":"LLM","slug":"LLM","count":1,"path":"api/categories/LLM.json"}],"tags":[{"name":"学习","slug":"学习","count":43,"path":"api/tags/学习.json"},{"name":"笔记本","slug":"笔记本","count":2,"path":"api/tags/笔记本.json"},{"name":"零碎的","slug":"零碎的","count":2,"path":"api/tags/零碎的.json"},{"name":"知识点","slug":"知识点","count":2,"path":"api/tags/知识点.json"},{"name":"深度学习","slug":"深度学习","count":1,"path":"api/tags/深度学习.json"},{"name":"大模型","slug":"大模型","count":1,"path":"api/tags/大模型.json"},{"name":"训练","slug":"训练","count":1,"path":"api/tags/训练.json"}],"toc":"","author":{"name":"Ausert","slug":"blog-author","avatar":"/img/Ausert.jpg","link":"/","description":"tech otakus save the world","socials":{"github":"https://github.com/AusertDream","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili.svg","link":"https://space.bilibili.com/102368527?spm_id_from=333.1007.0.0"},"codeforce":{"icon":"/svg/codeforces.svg","link":"https://codeforces.com/profile/Ausert"}}}},"mapped":true,"prev_post":{"title":"ACM小本本","uid":"4a9ea142753f2671aa4c5ecbc1f2c491","slug":"ACM小本本","date":"2022-11-09T12:43:41.000Z","updated":"2023-08-25T14:20:11.540Z","comments":true,"path":"api/articles/ACM小本本.json","keywords":null,"cover":"/img/codeforces.jpg","text":"这里是记录ACM知识点中一些零碎的东西，或者一些小的注意点啥的 1.使用二分模板的时候，当修改left值的时候，注意要让mid&#x3D;left+right+1&gt;&gt;1，不然会出现mid&#x3D;left然后死循环的出现2.快排和归并的本质就是分治，快排是先处理数据...","link":"","photos":[],"count_time":{"symbolsCount":"2k","symbolsTime":"2 mins."},"categories":[{"name":"ACM","slug":"ACM","count":42,"path":"api/categories/ACM.json"}],"tags":[{"name":"ACM","slug":"ACM","count":39,"path":"api/tags/ACM.json"},{"name":"学习","slug":"学习","count":43,"path":"api/tags/学习.json"},{"name":"笔记本","slug":"笔记本","count":2,"path":"api/tags/笔记本.json"},{"name":"零碎的","slug":"零碎的","count":2,"path":"api/tags/零碎的.json"},{"name":"知识点","slug":"知识点","count":2,"path":"api/tags/知识点.json"}],"author":{"name":"Ausert","slug":"blog-author","avatar":"/img/Ausert.jpg","link":"/","description":"tech otakus save the world","socials":{"github":"https://github.com/AusertDream","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili.svg","link":"https://space.bilibili.com/102368527?spm_id_from=333.1007.0.0"},"codeforce":{"icon":"/svg/codeforces.svg","link":"https://codeforces.com/profile/Ausert"}}}},"feature":true},"next_post":{"title":"2024年终总结","uid":"ce7691ff8f2ef9994a806e6cb0977c21","slug":"2024年终总结","date":"2024-12-29T15:29:06.724Z","updated":"2024-12-29T15:29:06.726Z","comments":true,"path":"api/articles/2024年终总结.json","keywords":null,"cover":"/img/Ausert.jpg","text":"一年的时间真的过的很快，转眼间2024年已经行将尾声。现在再回首看向2024年的自己，感觉2024年的自己上下起伏还是很大的。也是自高考失败，插班生失败之后，第一次做成功了一件事。或许在之后，拼尽全力但是考插失败的阴影能够逐渐散去吧。 这一年间，我都干了点啥呢？保研结算，进到同济...","link":"","photos":[],"count_time":{"symbolsCount":"2k","symbolsTime":"2 mins."},"categories":[{"name":"年终总结","slug":"年终总结","count":1,"path":"api/categories/年终总结.json"}],"tags":[{"name":"年终总结","slug":"年终总结","count":1,"path":"api/tags/年终总结.json"},{"name":"碎碎念","slug":"碎碎念","count":1,"path":"api/tags/碎碎念.json"}],"author":{"name":"Ausert","slug":"blog-author","avatar":"/img/Ausert.jpg","link":"/","description":"tech otakus save the world","socials":{"github":"https://github.com/AusertDream","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili.svg","link":"https://space.bilibili.com/102368527?spm_id_from=333.1007.0.0"},"codeforce":{"icon":"/svg/codeforces.svg","link":"https://codeforces.com/profile/Ausert"}}}},"feature":false}}